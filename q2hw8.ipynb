{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q2hw8.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOhUKc0CXchEqa0PBaQuEd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gracewindheim/gmwDataSci/blob/master/q2hw8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ZwB0ssy5wI",
        "colab_type": "text"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg3o0VCUzBFf",
        "colab_type": "text"
      },
      "source": [
        "Use Keras and Tensor Flow on colab to fit a prediction model for the fashion mnist data. Try 5 versions of the model with different numbers of hidden layers and dropout (of your choosing). Compare the test set accuracy of each of the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L07qN3-K2FPw",
        "colab_type": "code",
        "outputId": "fe31a358-ccbf-449c-f92f-f27df2d2fbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!pip install -U tensorflow_datasets\n",
        "import tensorflow as tf\n",
        "# Import TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Helper libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/41/8404fabb295025c1ced13bb150246f75770619889d8637afa523a4d09cdb/tensorflow_datasets-3.0.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.21.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.51.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (46.1.3)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 2.1.0\n",
            "    Uninstalling tensorflow-datasets-2.1.0:\n",
            "      Successfully uninstalled tensorflow-datasets-2.1.0\n",
            "Successfully installed tensorflow-datasets-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plbKsKVXI4X3",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjPYHZ8-2Sv0",
        "colab_type": "code",
        "outputId": "226003c8-9aad-455a-fc3c-6c41248a2fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']\n",
        "\n",
        "# Preprocessing data\n",
        "def normalize(images, labels):\n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255\n",
        "  return images, labels\n",
        "\n",
        "# The map function applies the normalize function to each element in the train\n",
        "# and test datasets\n",
        "train_dataset =  train_dataset.map(normalize)\n",
        "test_dataset  =  test_dataset.map(normalize)\n",
        "\n",
        "# The first time you use the dataset, the images will be loaded from disk\n",
        "# Caching will keep them in memory, making training faster\n",
        "train_dataset =  train_dataset.cache()\n",
        "test_dataset  =  test_dataset.cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset fashion_mnist/3.0.1 (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /root/tensorflow_datasets/fashion_mnist/3.0.1...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/fashion_mnist/3.0.1.incomplete0XQHXM/fashion_mnist-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/fashion_mnist/3.0.1.incomplete0XQHXM/fashion_mnist-test.tfrecord\n",
            "\u001b[1mDataset fashion_mnist downloaded and prepared to /root/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BLKRiAa4tQ_",
        "colab_type": "code",
        "outputId": "50050441-5083-48f7-8bd2-329ae214ee87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 60000\n",
            "Number of test examples:     10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1atCdQMo0gdy",
        "colab_type": "text"
      },
      "source": [
        "## Version 1\n",
        "1 hidden layer, 10% dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1oTlUU52t3W",
        "colab_type": "code",
        "outputId": "51cf27a8-5f60-4178-934d-ccdf83d6bc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset1 = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset1 = test_dataset.cache().batch(BATCH_SIZE)\n",
        "model1.fit(train_dataset1, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "\n",
        "test_loss, test_accuracy = model1.evaluate(test_dataset1, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5053 - accuracy: 0.8218\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3856 - accuracy: 0.8607\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3461 - accuracy: 0.8731\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3208 - accuracy: 0.8812\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3101 - accuracy: 0.8855\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3480 - accuracy: 0.8757\n",
            "Accuracy on test dataset: 0.8756999969482422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UNzBcGrD03VL"
      },
      "source": [
        "## Version 2\n",
        "3 hidden layers, 10% dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnWJnRXm2vZO",
        "colab_type": "code",
        "outputId": "6d1c8ab2-8d62-4829-cfc3-7e13560b8b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset2 = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset2 = test_dataset.cache().batch(BATCH_SIZE)\n",
        "model2.fit(train_dataset2, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "\n",
        "test_loss, test_accuracy = model2.evaluate(test_dataset2, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5303 - accuracy: 0.8084\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4010 - accuracy: 0.8537\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3664 - accuracy: 0.8669\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3471 - accuracy: 0.8711\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3265 - accuracy: 0.8789\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8728\n",
            "Accuracy on test dataset: 0.8727999925613403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk_IVCtx06du",
        "colab_type": "text"
      },
      "source": [
        "## Version 3\n",
        "5 hidden layers, 10% dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqVAdLRQ2wEI",
        "colab_type": "code",
        "outputId": "606fe005-d038-41a9-c6d6-a60c14cd82c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model3.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset3 = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset3 = test_dataset.cache().batch(BATCH_SIZE)\n",
        "model3.fit(train_dataset3, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "\n",
        "test_loss, test_accuracy = model3.evaluate(test_dataset3, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5769 - accuracy: 0.7933\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4189 - accuracy: 0.8496\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3904 - accuracy: 0.8605\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3747 - accuracy: 0.8662\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3495 - accuracy: 0.8748\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8669\n",
            "Accuracy on test dataset: 0.8669000267982483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG092-Au0-Ga",
        "colab_type": "text"
      },
      "source": [
        "## Version 4\n",
        "2 hidden layers, 40% dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLyZcKHL2wyI",
        "colab_type": "code",
        "outputId": "cd406e74-55f8-4ed3-bbed-e2856560fc15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model4.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset4 = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset4 = test_dataset.cache().batch(BATCH_SIZE)\n",
        "model4.fit(train_dataset4, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "\n",
        "test_loss, test_accuracy = model4.evaluate(test_dataset4, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6476 - accuracy: 0.7659\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4870 - accuracy: 0.8251\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4468 - accuracy: 0.8396\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4272 - accuracy: 0.8453\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4088 - accuracy: 0.8536\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8604\n",
            "Accuracy on test dataset: 0.8604000210762024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd3PHOUZ1BmN",
        "colab_type": "text"
      },
      "source": [
        "## Version 5\n",
        "2 hidden layer, 80% dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyp5rq102xaD",
        "colab_type": "code",
        "outputId": "8389c79c-4221-4987-b492-7a5d524a1d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.8),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.8),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model5.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset5 = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset5 = test_dataset.cache().batch(BATCH_SIZE)\n",
        "model5.fit(train_dataset5, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "\n",
        "test_loss, test_accuracy = model5.evaluate(test_dataset5, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5940 - accuracy: 0.3966\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2447 - accuracy: 0.5121\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1617 - accuracy: 0.5430\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1242 - accuracy: 0.5587\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.1065 - accuracy: 0.5659\n",
            "313/313 [==============================] - 0s 2ms/step - loss: 0.7824 - accuracy: 0.7116\n",
            "Accuracy on test dataset: 0.7116000056266785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzK88k_7ZU8p",
        "colab_type": "text"
      },
      "source": [
        "## Comparison\n",
        "\n",
        "Version 1 (1 hidden layer, 10% dropout). Accuracy = 87.6%\n",
        "\n",
        "Version 2 (3 hidden layers, 10% dropout). Accuracy = 87.3%\n",
        "\n",
        "Version 3 (5 hidden layers, 10% dropout). Accuracy = 86.7%\n",
        "\n",
        "Version 4 (2 hidden layers, 40% dropout). Accuracy = 86.0%\n",
        "\n",
        "Version 5 (2 hidden layers, 80% dropout). Accuracy = 71.2%\n",
        "\n",
        "\n",
        "Seems to perform better with fewer layers and fewer dropout."
      ]
    }
  ]
}