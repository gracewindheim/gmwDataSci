{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q4hw8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQ0vJH0164i+KkOnH9YDsk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gracewindheim/gmwDataSci/blob/master/q4hw8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oNGeegd02Ex",
        "colab_type": "text"
      },
      "source": [
        "# Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ocnr2GD001Y0",
        "colab_type": "text"
      },
      "source": [
        "Fit a multilayer neural network model on the SHHS data to predict whether rdi4p > 7 using the variables from the previous HW assigment. Compare the test set error with the penalized model from your previous HW."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKilHwx4040z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X variables = waist, gender, sex, bmi (gender, age_s1, bmi_s1, rdi4p)\n",
        "# y outcome = if rdi4p > 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLwtI85e1uKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpPta5fo1pkI",
        "colab_type": "code",
        "outputId": "08384c60-43e7-46c7-c415-edd514260a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "! if [ ! -e oasis.csv ]; \\\n",
        "then wget https://raw.githubusercontent.com/gracewindheim/gmwDataSci/master/shhs1.txt; \\\n",
        "fi;\n",
        "\n",
        "## Read in the data and display a few rows\n",
        "dat = pd.read_csv(\"shhs1.txt\", sep = \"\\t\")\n",
        "dat = dat.dropna()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 22:13:48--  https://raw.githubusercontent.com/gracewindheim/gmwDataSci/master/shhs1.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 740206 (723K) [text/plain]\n",
            "Saving to: ‘shhs1.txt.1’\n",
            "\n",
            "\rshhs1.txt.1           0%[                    ]       0  --.-KB/s               \rshhs1.txt.1         100%[===================>] 722.86K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-04-28 22:13:48 (10.8 MB/s) - ‘shhs1.txt.1’ saved [740206/740206]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pptid</th>\n",
              "      <th>waist</th>\n",
              "      <th>COPD15</th>\n",
              "      <th>ASTHMA15</th>\n",
              "      <th>slp_lat</th>\n",
              "      <th>time_bed</th>\n",
              "      <th>timest1p</th>\n",
              "      <th>timest2p</th>\n",
              "      <th>times34p</th>\n",
              "      <th>timeremp</th>\n",
              "      <th>rdi4p</th>\n",
              "      <th>StLOutP</th>\n",
              "      <th>StOnsetP</th>\n",
              "      <th>SlpPrdP</th>\n",
              "      <th>Staging1</th>\n",
              "      <th>Staging2</th>\n",
              "      <th>Staging3</th>\n",
              "      <th>Staging4</th>\n",
              "      <th>Staging5</th>\n",
              "      <th>RestAn1</th>\n",
              "      <th>RestAn2</th>\n",
              "      <th>RestAn3</th>\n",
              "      <th>RestAn4</th>\n",
              "      <th>HTNDerv_s1</th>\n",
              "      <th>shhs1_tcvd</th>\n",
              "      <th>gender</th>\n",
              "      <th>age_s1</th>\n",
              "      <th>smokstat_s1</th>\n",
              "      <th>WASO</th>\n",
              "      <th>bmi_s1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>440.5</td>\n",
              "      <td>6.258322</td>\n",
              "      <td>60.852196</td>\n",
              "      <td>19.307590</td>\n",
              "      <td>13.581891</td>\n",
              "      <td>1.438083</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>375.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>2.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>21.777553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>225.0</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>65.659340</td>\n",
              "      <td>16.758242</td>\n",
              "      <td>16.758242</td>\n",
              "      <td>17.802198</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>32.950680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>431.5</td>\n",
              "      <td>4.881451</td>\n",
              "      <td>40.306835</td>\n",
              "      <td>42.817295</td>\n",
              "      <td>11.994421</td>\n",
              "      <td>4.853556</td>\n",
              "      <td>167</td>\n",
              "      <td>167</td>\n",
              "      <td>358.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>24.114150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>358.5</td>\n",
              "      <td>2.990033</td>\n",
              "      <td>29.401993</td>\n",
              "      <td>52.325581</td>\n",
              "      <td>15.282393</td>\n",
              "      <td>0.797342</td>\n",
              "      <td>54</td>\n",
              "      <td>82</td>\n",
              "      <td>301.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.5</td>\n",
              "      <td>20.185185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pptid  waist  COPD15  ASTHMA15  ...  age_s1  smokstat_s1  WASO     bmi_s1\n",
              "0      1   86.0     0.0       0.0  ...      55          2.0  65.0  21.777553\n",
              "1      2  107.0     0.0       0.0  ...      78          0.0  43.0  32.950680\n",
              "2      3   82.0     0.0       0.0  ...      77          0.0  73.0  24.114150\n",
              "3      4   85.0     0.0       0.0  ...      48          0.0  43.5  20.185185\n",
              "\n",
              "[4 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-s6scWN3Hel",
        "colab_type": "code",
        "outputId": "5bed1e50-3963-4576-b2fe-78e6894b7253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Create binary variable that assigns if rdi4p > 7\n",
        "dat['rdi4pBin'] = np.where(dat['rdi4p'] > 7, 1, 0)\n",
        "\n",
        "# isolate x and y variables\n",
        "dataset = dat[['bmi_s1'] + ['age_s1'] + ['gender'] + ['waist'] + ['rdi4pBin']]\n",
        "\n",
        "# split data\n",
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "## These commands operate on the training and testing\n",
        "## data to remove the y outcome column and save it\n",
        "train_outcome = train_dataset.pop('rdi4pBin')\n",
        "test_outcome = test_dataset.pop('rdi4pBin')\n",
        "\n",
        "train_stats = train_dataset.describe().transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bmi_s1</th>\n",
              "      <td>2318.0</td>\n",
              "      <td>28.133346</td>\n",
              "      <td>5.063205</td>\n",
              "      <td>18.0</td>\n",
              "      <td>24.67128</td>\n",
              "      <td>27.44604</td>\n",
              "      <td>30.791183</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_s1</th>\n",
              "      <td>2318.0</td>\n",
              "      <td>62.973253</td>\n",
              "      <td>10.992687</td>\n",
              "      <td>39.0</td>\n",
              "      <td>55.00000</td>\n",
              "      <td>63.00000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>2318.0</td>\n",
              "      <td>0.485764</td>\n",
              "      <td>0.499905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waist</th>\n",
              "      <td>2318.0</td>\n",
              "      <td>96.705854</td>\n",
              "      <td>13.527326</td>\n",
              "      <td>67.0</td>\n",
              "      <td>88.00000</td>\n",
              "      <td>96.00000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>135.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         count       mean        std  ...       50%         75%    max\n",
              "bmi_s1  2318.0  28.133346   5.063205  ...  27.44604   30.791183   50.0\n",
              "age_s1  2318.0  62.973253  10.992687  ...  63.00000   71.000000   90.0\n",
              "gender  2318.0   0.485764   0.499905  ...   0.00000    1.000000    1.0\n",
              "waist   2318.0  96.705854  13.527326  ...  96.00000  105.000000  135.0\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJBhfn_iTcxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize data\n",
        "mn = train_stats['mean']\n",
        "sd = train_stats['std']\n",
        "normed_train_data = train_dataset.apply(lambda row: (row - mn) / sd, axis = 1)\n",
        "normed_test_data = test_dataset.apply(lambda row: (row - mn) / sd, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO4lJRgxUj1n",
        "colab_type": "code",
        "outputId": "fba38e1f-b51c-4c57-8ca4-aa191f64338a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# make data floats\n",
        "x_train = normed_train_data.astype('float')\n",
        "x_test = normed_test_data.astype('float')\n",
        "\n",
        "y_train = train_outcome\n",
        "y_test = test_outcome"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2318, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yESCj0qwT6Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build model\n",
        "model = keras.Sequential([\n",
        "  keras.layers.Dense(64, activation='relu', input_dim=4),\n",
        "  keras.layers.Dense(64, activation='relu'),\n",
        "  keras.layers.Dropout(0.2),\n",
        "  keras.layers.Dense(64, activation='relu'),\n",
        "  keras.layers.Dropout(0.2),\n",
        "  keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOwzTX-6UkW-",
        "colab_type": "code",
        "outputId": "b5a33423-3a64-4b37-c838-8945fc08bde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "training = model.fit(x_train, y_train, epochs = 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.7661 - accuracy: 0.6462\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.6812\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6795\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6816\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6756\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.6700\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6851\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5993 - accuracy: 0.6678\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6894\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6976\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.6963\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6881\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6730\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6846\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6821\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.6898\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6661\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.6885\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.6920\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.6877\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6864\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.6984\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.6915\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.6911\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6976\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.6885\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.6972\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7006\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.6855\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7062\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.6963\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7019\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.6993\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.6911\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.6993\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7010\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.6963\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7002\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7019\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7019\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.6937\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6855\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.6933\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.6937\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7015\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7045\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7053\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.6980\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7084\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.6959\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.6933\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.6989\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7045\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7002\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.6950\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7015\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7036\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.6980\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.6997\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7006\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.6950\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7041\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7053\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7006\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.6898\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.6993\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7088\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7006\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7015\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7053\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.6959\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7032\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7032\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7006\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7161\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7045\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7045\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7053\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7092\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7032\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.6959\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7131\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7036\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.6972\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7015\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7036\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7127\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.6959\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7170\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7028\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.6980\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7118\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7075\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7015\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7097\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7071\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7148\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7140\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7088\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2saaFE_ZC74",
        "colab_type": "code",
        "outputId": "16dd3010-4108-45c4-cec8-3615b093fc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 - 0s - loss: 0.5708 - accuracy: 0.7168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5707707405090332, 0.7167530059814453]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvtPxFIQa1Yd",
        "colab_type": "text"
      },
      "source": [
        "## Comparison\n",
        "Multilayer neural network yielded 71.7% accuracy. My penalized model from last HW yielded an accuracy of around 81.2%."
      ]
    }
  ]
}